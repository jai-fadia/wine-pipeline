{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('py37': conda)",
   "display_name": "Python 3.7.7 64-bit ('py37': conda)",
   "metadata": {
    "interpreter": {
     "hash": "441a4cfc3e345b5da2414d62702626644577ab79ccb5f8bcb7255a7bd1563bfc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Objective: to compare 3 models (SVM, RandomForest, MLP) systematically and determine the best one to predict the target in the wine dataset.\n",
    "- Author: Jai Fadia\n",
    "- Python 3.7.7 64-bit Anaconda"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.datasets"
   ]
  },
  {
   "source": [
    "### Step 1: Import dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "data = sklearn.datasets.load_wine(as_frame = True)['frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alcohol</th>\n      <th>malic_acid</th>\n      <th>ash</th>\n      <th>alcalinity_of_ash</th>\n      <th>magnesium</th>\n      <th>total_phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoid_phenols</th>\n      <th>proanthocyanins</th>\n      <th>color_intensity</th>\n      <th>hue</th>\n      <th>od280/od315_of_diluted_wines</th>\n      <th>proline</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127.0</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100.0</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101.0</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113.0</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118.0</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# view data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "alcohol                         0\n",
       "malic_acid                      0\n",
       "ash                             0\n",
       "alcalinity_of_ash               0\n",
       "magnesium                       0\n",
       "total_phenols                   0\n",
       "flavanoids                      0\n",
       "nonflavanoid_phenols            0\n",
       "proanthocyanins                 0\n",
       "color_intensity                 0\n",
       "hue                             0\n",
       "od280/od315_of_diluted_wines    0\n",
       "proline                         0\n",
       "target                          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# check for null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "source": [
    "### Step 2: Split dependent and independent variables, split into training and testing sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split target and predictor variables\n",
    "x = data.drop(labels = 'target', axis = 1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "source": [
    "### Step 3: Create pipeline for all 3 models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary in which to store inputs to pipeline for each model\n",
    "pipe = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store SVM inputs\n",
    "pipe['svm'] = {}\n",
    "\n",
    "# use the standardscaler to scale variables from the dataframe and then apply the SVC classifier\n",
    "pipe['svm']['steps'] = [('scaler', StandardScaler()), ('SVM', SVC())]\n",
    "pipe['svm']['pipe'] = Pipeline(pipe['svm']['steps'])\n",
    "\n",
    "# using RandomSearchCV to determine the optimial parameters, so specify the distributions of the parameters\n",
    "pipe['svm']['parameters'] = {\n",
    "    'SVM__C' : scipy.stats.expon(scale = 0.1),\n",
    "    'SVM__gamma' : scipy.stats.expon(scale = 0.1)\n",
    "    }\n",
    "\n",
    "# create the model object and specify the number of iterations to test\n",
    "pipe['svm']['model'] = RandomizedSearchCV(pipe['svm']['pipe'],\n",
    "    param_distributions = pipe['svm']['parameters'],\n",
    "    n_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store RandomForest inputs\n",
    "pipe['rf'] = {}\n",
    "\n",
    "# use the standardscaler to scale variables from the dataframe and then apply the RandomForestClassifier\n",
    "pipe['rf']['steps'] = [('scaler', StandardScaler()), ('RF', RandomForestClassifier())]\n",
    "pipe['rf']['pipe'] = Pipeline(pipe['rf']['steps'])\n",
    "\n",
    "# using RandomSearchCV to determine the optimial parameters, so specify the distributions of the parameters\n",
    "pipe['rf']['parameters'] = {\n",
    "    'RF__max_depth' : scipy.stats.randint.rvs(low = 1, high = 1000, size = 1),\n",
    "    'RF__n_estimators' : scipy.stats.randint.rvs(low = 1, high = 1000, size = 1),\n",
    "    'RF__min_samples_split' : scipy.stats.randint.rvs(low = 1, high = 100, size = 1),\n",
    "    'RF__min_samples_leaf' : scipy.stats.randint.rvs(low = 1, high = 100, size = 1),\n",
    "    'RF__bootstrap' : scipy.stats.randint.rvs(low = 0, high = 1, size = 1)\n",
    "}\n",
    "\n",
    "# create the model object and specify the number of iterations to test\n",
    "pipe['rf']['model'] = RandomizedSearchCV(pipe['rf']['pipe'],\n",
    "    param_distributions = pipe['rf']['parameters'],\n",
    "    n_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store MLP inputs\n",
    "pipe['mlp'] = {}\n",
    "\n",
    "# use the standardscaler to scale variables from the dataframe and then apply the MLPClassifier\n",
    "pipe['mlp']['steps'] = [('scaler', StandardScaler()), ('MLP', MLPClassifier())]\n",
    "pipe['mlp']['pipe'] = Pipeline(pipe['mlp']['steps'])\n",
    "\n",
    "# using RandomSearchCV to determine the optimial parameters, so specify the distributions of the parameters\n",
    "# randomizing the architecture of the neural network using varying depths and number of neurons per layer\n",
    "pipe['mlp']['parameters'] = {\n",
    "    'MLP__activation' : ['relu', 'logistic', 'tanh'],\n",
    "    'MLP__alpha' : scipy.stats.expon(scale = 0.0001),\n",
    "    'MLP__hidden_layer_sizes' : scipy.stats.randint.rvs(low = 1, high = 10, size = scipy.stats.randint.rvs(low = 1, high = 10, size = 1))\n",
    "}\n",
    "\n",
    "# create the model object and specify the number of iterations to test\n",
    "pipe['mlp']['model'] = RandomizedSearchCV(pipe['mlp']['pipe'],\n",
    "    param_distributions = pipe['mlp']['parameters'],\n",
    "    n_iter = 10000)"
   ]
  },
  {
   "source": [
    "### Step 4: Train models and evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score:\t\t0.9722222222222222\n{'SVM__C': 0.2706563239598662, 'SVM__gamma': 0.03130441834741778}\n"
     ]
    }
   ],
   "source": [
    "# train SVM, evaluate its performance on the testing set, and output the score and optimal parameters\n",
    "pipe['svm']['model'].fit(x_train, y_train)\n",
    "\n",
    "print('Score:\\t\\t{}'.format(pipe['svm']['model'].score(x_test, y_test)))\n",
    "print(pipe['svm']['model'].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score:\t\t0.9166666666666666\n{'RF__n_estimators': 403, 'RF__min_samples_split': 43, 'RF__min_samples_leaf': 12, 'RF__max_depth': 505, 'RF__bootstrap': 0}\n"
     ]
    }
   ],
   "source": [
    "# train RF, evaluate its performance on the testing set, and output the score and optimal parameters\n",
    "pipe['rf']['model'].fit(x_train, y_train)\n",
    "\n",
    "print('Score:\\t\\t{}'.format(pipe['rf']['model'].score(x_test, y_test)))\n",
    "print(pipe['rf']['model'].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score:\t\t0.75\n{'MLP__activation': 'relu', 'MLP__alpha': 6.106042670091599e-05, 'MLP__hidden_layer_sizes': 7}\n"
     ]
    }
   ],
   "source": [
    "# train MLP, evaluate its performance on the testing set, and output the score and optimal parameters\n",
    "pipe['mlp']['model'].fit(x_train, y_train)\n",
    "\n",
    "print('Score:\\t\\t{}'.format(pipe['mlp']['model'].score(x_test, y_test)))\n",
    "print(pipe['mlp']['model'].best_params_)"
   ]
  },
  {
   "source": [
    "### Conclusion\n",
    "The SVM model with C = ~0.27 and gamma = ~0.03 is the optimal model for this use case."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}